{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7a080b-2765-4116-8f68-42ba2e460b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from movi import MoviDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import io\n",
    "\n",
    "import matplotlib.patches\n",
    "\n",
    "from IPython.display import HTML as html_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283cb42f-6e43-4382-beb0-9b7ad99f25c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/om2/user/yyf/miniconda/bin/pip\", line 7, in <module>\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f19e83-ed51-42c4-b298-79cff71ffef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_to_rgb(seg, palette=None, num_objects=None, bg_color=(0, 0, 0)):\n",
    "  if num_objects is None:\n",
    "    num_objects = np.max(seg)  # assume consecutive numbering\n",
    "  num_objects += 1  # background\n",
    "  if palette is None:\n",
    "    palette = [bg_color] + sns.color_palette('hls', num_objects-1)\n",
    "\n",
    "  seg_img = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.float32)\n",
    "  for i in range(num_objects):\n",
    "    seg_img[np.nonzero(seg[:, :, 0] == i)] = palette[i]\n",
    "  return seg_img\n",
    "\n",
    "def depth_to_rgb(depth, colormap=matplotlib.cm.viridis_r, sqrt=True):\n",
    "  cmap = np.array(colormap.colors)\n",
    "  if sqrt:\n",
    "    d = np.round(np.sqrt((depth[..., 0] / 65535).clip(0, 1.)) * 255).astype(np.uint8)\n",
    "  else:\n",
    "    d = np.round(depth[..., 0] // 256).astype(np.uint8)\n",
    "  return cmap[d]\n",
    "\n",
    "def flow_to_rgb(vec, flow_mag_range=None, white_bg=False):\n",
    "  height, width = vec.shape[:2]\n",
    "  scaling = 50. / (height**2 + width**2)**0.5\n",
    "  direction = (np.arctan2(vec[..., 0], vec[..., 1]) + np.pi) / (2 * np.pi)\n",
    "  norm = np.linalg.norm(vec, axis=-1)\n",
    "  if flow_mag_range is None:\n",
    "    flow_mag_range = norm.min(), norm.max()\n",
    "  magnitude = np.clip((norm - flow_mag_range[0]) * scaling, 0., 1.)\n",
    "  if white_bg == True:\n",
    "    value = np.ones_like(direction)\n",
    "    hsv = np.stack([direction, magnitude, saturation], axis=-1)\n",
    "  else:\n",
    "    saturation = np.ones_like(direction)\n",
    "    hsv = np.stack([direction, saturation , magnitude], axis=-1)\n",
    "  rgb = matplotlib.colors.hsv_to_rgb(hsv)\n",
    "  return rgb\n",
    "\n",
    "def plot_bboxes(sample, palette=None, linewidth=1):\n",
    "  resolution = sample[\"video\"].shape[-3:-1]\n",
    "\n",
    "  bboxes = sample[\"instances\"][\"bboxes\"]\n",
    "  bbox_frames = sample[\"instances\"][\"bbox_frames\"]\n",
    "  num_objects = bboxes.shape[0]\n",
    "  if palette is None:\n",
    "      palette = sns.color_palette('hls', num_objects)\n",
    "  images = []\n",
    "  for t, rgb in enumerate(sample[\"video\"]):\n",
    "    fig, ax = plt.subplots(figsize=(resolution[0]/100, resolution[1]/100), dpi=132.5)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(rgb)\n",
    "    for k in range(num_objects):\n",
    "      if t in bbox_frames[k]:\n",
    "        idx = np.nonzero(bbox_frames[k] == t)[0][0]\n",
    "\n",
    "        miny, minx, maxy, maxx = bboxes[k][idx]\n",
    "        miny = max(1, miny*resolution[0])\n",
    "        minx = max(1, minx*resolution[1])\n",
    "        maxy = min(resolution[0]-1, maxy*resolution[0])\n",
    "        maxx = min(resolution[1]-1, maxx*resolution[1])\n",
    "        rect = matplotlib.patches.Rectangle([minx, miny], maxx-minx, maxy-miny,\n",
    "                                            linewidth=linewidth, edgecolor=palette[k],\n",
    "                                            facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "\n",
    "    for k in range(num_objects):\n",
    "      x, y = sample[\"instances\"][\"image_positions\"][k, t] * resolution\n",
    "      if np.all(1 < y < resolution[0]-1) and np.all(1 < x < resolution[1]-1):\n",
    "        ax.scatter(x, y, marker=\"X\", s=5, color=palette[k])\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format = \"png\", bbox_inches = 'tight', pad_inches = 0, dpi=132.5)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    img = PIL.Image.open(buf)\n",
    "    images.append(np.array(img)[..., :3])\n",
    "  return images\n",
    "\n",
    "def getsize(arr): \n",
    "  if isinstance(arr, np.ndarray):\n",
    "    return arr.nbytes\n",
    "  elif isinstance(arr, dict):\n",
    "    return sum([getsize(v) for v in arr.values()])\n",
    "  elif isinstance(arr, list):\n",
    "    return sum([getsize(v) for v in arr])\n",
    "  else:\n",
    "    return sys.getsizeof(arr)\n",
    "\n",
    "def print_instance_ids(sample, ds_info, palette=None):\n",
    "  if palette is None:\n",
    "    palette = sns.color_palette('hls', sample[\"metadata\"][\"num_instances\"])\n",
    "  out = ''\n",
    "  if \"asset_id\" in sample[\"instances\"]:\n",
    "    ids = [s.decode() for s in sample[\"instances\"][\"asset_id\"]]\n",
    "  else:\n",
    "    labels = []\n",
    "    if \"size_label\" in sample[\"instances\"]:\n",
    "      labels.append([ds_info.features[\"instances\"][\"size_label\"].names[k]\n",
    "                       for k in sample[\"instances\"][\"size_label\"]])\n",
    "    if \"color_label\" in sample[\"instances\"]:\n",
    "      labels.append([ds_info.features[\"instances\"][\"color_label\"].names[k]\n",
    "                       for k in sample[\"instances\"][\"color_label\"]])\n",
    "    labels.append([ds_info.features[\"instances\"][\"material_label\"].names[k]\n",
    "                       for k in sample[\"instances\"][\"material_label\"]])\n",
    "    labels.append([ds_info.features[\"instances\"][\"shape_label\"].names[k]\n",
    "                   for k in sample[\"instances\"][\"shape_label\"]])\n",
    "    ids = [\" \".join(x) for x in zip(*labels)]\n",
    "\n",
    "  for i, (color, asset_id) in enumerate(zip(palette, ids)):\n",
    "    color_hex = '#%02x%02x%02x' % tuple(int(x*255) for x in color)\n",
    "    out += f'{i}. <b><text style=color:{color_hex}>{asset_id}</text></b><br/>'\n",
    "    \n",
    "  return html_print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7b20b8-0e3d-443b-a2af-8962bd8afec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 11:57:46.724893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /net/vast-storage/scratch/vast/tenenbaum/yyf/miniconda/lib/python3.9/site-packages/cv2/../../lib64:/cm/shared/openmind/cuda/11.1/lib64:/cm/shared/openmind/cuda/11.1/lib64\n",
      "2022-04-29 11:57:46.724942: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "md = DataLoader(MoviDataset(\"/om2/user/yyf/MOVI/movi_a/256x256/1.0.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4bdb9ce-c8d8-478e-90be-07c9443077fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/om2/user/yyf/MOVI/movi_a/256x256/1.0.0/movi_a-train.tfrecord-00076-of-01024; No such file or directory [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_171550/2729123982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/unsupervised_object_discovery/data/movi.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_utils.py\u001b[0m in \u001b[0;36m_eager_dataset_iterator\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_eager_dataset_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNumpyElem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_elem_to_numpy_eager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    820\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2921\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2924\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om2/user/yyf/miniconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /om2/user/yyf/MOVI/movi_a/256x256/1.0.0/movi_a-train.tfrecord-00076-of-01024; No such file or directory [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "batch = next(iter(md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76500409-0b84-4245-8533-740f6a73c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': tensor([[[[[111, 111, 112,  ..., 110, 110, 110],\n",
       "            [111, 112, 111,  ..., 110, 110, 110],\n",
       "            [110, 110, 110,  ..., 111, 109, 111],\n",
       "            ...,\n",
       "            [112, 112, 113,  ..., 129, 128, 128],\n",
       "            [112, 112, 112,  ..., 128, 128, 129],\n",
       "            [112, 112, 112,  ..., 128, 129, 128]],\n",
       " \n",
       "           [[111, 111, 112,  ..., 110, 110, 110],\n",
       "            [111, 112, 111,  ..., 110, 110, 110],\n",
       "            [110, 110, 110,  ..., 111, 109, 111],\n",
       "            ...,\n",
       "            [111, 111, 112,  ..., 127, 126, 126],\n",
       "            [111, 111, 111,  ..., 127, 126, 127],\n",
       "            [111, 111, 111,  ..., 126, 127, 126]],\n",
       " \n",
       "           [[111, 111, 112,  ..., 110, 110, 110],\n",
       "            [111, 111, 111,  ..., 110, 110, 109],\n",
       "            [110, 110, 110,  ..., 111, 109, 111],\n",
       "            ...,\n",
       "            [110, 110, 110,  ..., 124, 123, 123],\n",
       "            [110, 109, 110,  ..., 124, 123, 124],\n",
       "            [109, 110, 109,  ..., 123, 124, 123]]],\n",
       " \n",
       " \n",
       "          [[[111, 111, 112,  ..., 110, 110, 110],\n",
       "            [111, 112, 111,  ..., 110, 110, 110],\n",
       "            [110, 110, 110,  ..., 111, 109, 111],\n",
       "            ...,\n",
       "            [112, 112, 112,  ..., 129, 128, 127],\n",
       "            [112, 112, 112,  ..., 128, 127, 128],\n",
       "            [111, 112, 112,  ..., 128, 128, 127]],\n",
       " \n",
       "           [[111, 111, 112,  ..., 110, 110, 110],\n",
       "            [111, 112, 111,  ..., 110, 110, 110],\n",
       "            [110, 110, 110,  ..., 111, 109, 111],\n",
       "            ...,\n",
       "            [111, 111, 111,  ..., 127, 126, 126],\n",
       "            [111, 111, 111,  ..., 126, 126, 127],\n",
       "            [110, 111, 111,  ..., 126, 127, 126]],\n",
       " \n",
       "           [[111, 111, 112,  ..., 110, 110, 110],\n",
       "            [111, 111, 111,  ..., 110, 110, 109],\n",
       "            [110, 110, 110,  ..., 111, 109, 111],\n",
       "            ...,\n",
       "            [110, 110, 110,  ..., 124, 123, 123],\n",
       "            [110, 109, 110,  ..., 123, 123, 124],\n",
       "            [109, 109, 109,  ..., 123, 124, 123]]]]], dtype=torch.uint8),\n",
       " 'objects': tensor([[[[[0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "          [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            ...,\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0],\n",
       "            [0, 0, 0,  ..., 0, 0, 0]]]]], dtype=torch.uint8),\n",
       " 'flow': tensor([[[[[39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            ...,\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.]],\n",
       " \n",
       "           [[39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            ...,\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.]]],\n",
       " \n",
       " \n",
       "          [[[39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            ...,\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.]],\n",
       " \n",
       "           [[39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            ...,\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.],\n",
       "            [39329., 39329., 39329.,  ..., 39329., 39329., 39329.]]]]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8137c41-fecd-48c4-b532-37d948754001",
   "metadata": {},
   "outputs": [],
   "source": [
    "minv, maxv = example[\"metadata\"][\"forward_flow_range\"]\n",
    "forward_flow = example[\"forward_flow\"] / 65535 * (maxv - minv) + minv\n",
    "\n",
    "minv, maxv = example[\"metadata\"][\"backward_flow_range\"]\n",
    "backward_flow = example[\"backward_flow\"] / 65535 * (maxv - minv) + minv\n",
    "\n",
    "minv, maxv = example[\"metadata\"][\"depth_range\"]\n",
    "depth = example[\"depth\"] / 65535 * (maxv - minv) + minv\n",
    "\n",
    "media.show_videos({\"rgb\": example[\"video\"], \n",
    "                   \"segmentation\": [segmentation_to_rgb(s, num_objects=example[\"metadata\"][\"num_instances\"])\n",
    "                                    for s in example[\"segmentations\"]],\n",
    "                   \"depth\": depth_to_rgb(example[\"depth\"], sqrt=True),\n",
    "                   \"normal\": example[\"normal\"],\n",
    "                   \"forward_flow\": flow_to_rgb(forward_flow, white_bg=False),\n",
    "                   \"backward_flow\": flow_to_rgb(backward_flow, white_bg=False),\n",
    "                   \"object_coordinates\": example[\"object_coordinates\"], \n",
    "                   \"bboxes/center_of_mass\": plot_bboxes(example),\n",
    "                   },\n",
    "                fps=12,\n",
    "                columns=4,\n",
    "                codec=\"gif\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
